{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7636864,"sourceType":"datasetVersion","datasetId":4450438}],"dockerImageVersionId":30775,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport albumentations as A\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\nfrom pathlib import Path\nimport shutil","metadata":{"execution":{"iopub.status.busy":"2024-11-03T09:55:51.921517Z","iopub.execute_input":"2024-11-03T09:55:51.922086Z","iopub.status.idle":"2024-11-03T09:56:14.415781Z","shell.execute_reply.started":"2024-11-03T09:55:51.922027Z","shell.execute_reply":"2024-11-03T09:56:14.414623Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/albumentations/check_version.py:49: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\n  data = fetch_version_info()\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport os\nimport cv2\nimport albumentations as A\nimport matplotlib.pyplot as plt\n\n# Define the path to the training images\ntrain_images_path = '/kaggle/input/ua-detrac-dataset/content/UA-DETRAC/DETRAC_Upload/images/train'\n\nmax_batches = 200\nnum_batch_count= 0\n\n# Generator to load images in batches\ndef load_images_in_batches(folder, batch_size=50):\n    images = []\n    filenames = []\n    batch_count = 0\n    global num_batch_count\n    print(num_batch_count)\n    for filename in os.listdir(folder):\n        if filename.endswith(\".jpg\"):  # Assuming images are in JPG format\n            img = cv2.imread(os.path.join(folder, filename))\n            if img is not None:\n                images.append(img)\n                filenames.append(Path(filename).name)\n                batch_count += 1\n                \n        # Yield the batch if the count hits batch_size\n        if batch_count == batch_size:\n            yield images, filenames\n            images = []  # Reset for next batch\n            filenames = []  # Reset for next batch\n            batch_count = 0\n            num_batch_count += 1  # Increment batch counter\n            \n        # Stop yielding if max_batches is reached\n        if num_batch_count >= max_batches:\n            break\n    # Yield the remaining images if any\n    if images:\n        yield images, filenames\n\nbatch_size = 5\n# Load a small batch of images for demonstration (e.g., first batch)\nimage_batches = load_images_in_batches(train_images_path, batch_size=batch_size)\n# first_batch = next(image_batches)  # Get the first batch\n# for _ in image_batches:A\n#     batch = next(image_batch)    \n\n# Define augmentation functions\ndef add_fog(image):\n    aug = A.Compose([A.RandomFog(fog_coef_lower=0.3, fog_coef_upper=0.6, alpha_coef=0.1, p=1.0)])\n    augmented = aug(image=image)\n    return augmented['image']\n\ndef add_rain(image):\n    aug = A.Compose([A.RandomRain(slant_lower=-10, slant_upper=10, drop_length=20, drop_width=1, blur_value=3, brightness_coefficient=0.8, rain_type='heavy', p=1.0)])\n    augmented = aug(image=image)\n    return augmented['image']\n\ndef add_snow(image):\n    aug = A.Compose([A.RandomSnow(snow_point_lower=0.3, snow_point_upper=0.5, brightness_coeff=2.5, p=1.0)])\n    augmented = aug(image=image)\n    return augmented['image']\n\ndef adjust_brightness_contrast(image):\n    aug = A.Compose([A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=1.0)])\n    augmented = aug(image=image)\n    return augmented['image']\n\n# Define output folder for saving augmented images\noutput_folder = '/kaggle/working'\nos.makedirs(output_folder, exist_ok=True)\n\nweather = ['fog','rain','snow']\nfor weather_singular in weather: # weather_singular is bad naming\n    os.system(f\"mkdir {os.path.join(output_folder, 'images_'+ weather_singular)}\")\n    os.system(f\"mkdir {os.path.join(output_folder, 'labels_'+ weather_singular)}\")\nos.listdir(output_folder)\n\n        \nk = 0\nbacth_generator = load_images_in_batches(train_images_path, batch_size)\nfor (batch,filenames) in bacth_generator:\n    # batch = next(image_batches) \n    # Applying augmentations to the first batch of images and displaying them\n    for i, (image, filename) in enumerate(zip(batch,filenames)):\n        fog_image = add_fog(image)\n        rain_image = add_rain(image)\n        snow_image = add_snow(image)\n        bright_contrast_image = adjust_brightness_contrast(image)\n\n        # Save the augmented images to the output folder\n        augmented_images = [add_fog(image), add_rain(image), add_snow(image)]\n        input_label_path = Path(os.path.join('/kaggle/input/ua-detrac-dataset/content/UA-DETRAC/DETRAC_Upload/labels/train',Path(filename).stem+\".txt\"))\n        if not input_label_path.exists():\n            continue\n        for j, aug_image in enumerate(augmented_images):\n            output_path = os.path.join(output_folder, 'images_'+ weather[j], filename)\n            cv2.imwrite(output_path, aug_image)\n            #             print(output_path)\n            \n            output_label_path = os.path.join(output_folder, 'labels_'+ weather[j], Path(filename).stem+\".txt\")\n            shutil.copy(input_label_path, output_label_path)\n            #             print(output_label_path)\n    print(f\"Augmented images saved in {output_folder} {k}-th batch\")\n    k+=1","metadata":{"execution":{"iopub.status.busy":"2024-11-03T09:56:14.417884Z","iopub.execute_input":"2024-11-03T09:56:14.418453Z","iopub.status.idle":"2024-11-03T10:18:46.899113Z","shell.execute_reply.started":"2024-11-03T09:56:14.418409Z","shell.execute_reply":"2024-11-03T10:18:46.897795Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"0\nAugmented images saved in /kaggle/working 0-th batch\nAugmented images saved in /kaggle/working 1-th batch\nAugmented images saved in /kaggle/working 2-th batch\nAugmented images saved in /kaggle/working 3-th batch\nAugmented images saved in /kaggle/working 4-th batch\nAugmented images saved in /kaggle/working 5-th batch\nAugmented images saved in /kaggle/working 6-th batch\nAugmented images saved in /kaggle/working 7-th batch\nAugmented images saved in /kaggle/working 8-th batch\nAugmented images saved in /kaggle/working 9-th batch\nAugmented images saved in /kaggle/working 10-th batch\nAugmented images saved in /kaggle/working 11-th batch\nAugmented images saved in /kaggle/working 12-th batch\nAugmented images saved in /kaggle/working 13-th batch\nAugmented images saved in /kaggle/working 14-th batch\nAugmented images saved in /kaggle/working 15-th batch\nAugmented images saved in /kaggle/working 16-th batch\nAugmented images saved in /kaggle/working 17-th batch\nAugmented images saved in /kaggle/working 18-th batch\nAugmented images saved in /kaggle/working 19-th batch\nAugmented images saved in /kaggle/working 20-th batch\nAugmented images saved in /kaggle/working 21-th batch\nAugmented images saved in /kaggle/working 22-th batch\nAugmented images saved in /kaggle/working 23-th batch\nAugmented images saved in /kaggle/working 24-th batch\nAugmented images saved in /kaggle/working 25-th batch\nAugmented images saved in /kaggle/working 26-th batch\nAugmented images saved in /kaggle/working 27-th batch\nAugmented images saved in /kaggle/working 28-th batch\nAugmented images saved in /kaggle/working 29-th batch\nAugmented images saved in /kaggle/working 30-th batch\nAugmented images saved in /kaggle/working 31-th batch\nAugmented images saved in /kaggle/working 32-th batch\nAugmented images saved in /kaggle/working 33-th batch\nAugmented images saved in /kaggle/working 34-th batch\nAugmented images saved in /kaggle/working 35-th batch\nAugmented images saved in /kaggle/working 36-th batch\nAugmented images saved in /kaggle/working 37-th batch\nAugmented images saved in /kaggle/working 38-th batch\nAugmented images saved in /kaggle/working 39-th batch\nAugmented images saved in /kaggle/working 40-th batch\nAugmented images saved in /kaggle/working 41-th batch\nAugmented images saved in /kaggle/working 42-th batch\nAugmented images saved in /kaggle/working 43-th batch\nAugmented images saved in /kaggle/working 44-th batch\nAugmented images saved in /kaggle/working 45-th batch\nAugmented images saved in /kaggle/working 46-th batch\nAugmented images saved in /kaggle/working 47-th batch\nAugmented images saved in /kaggle/working 48-th batch\nAugmented images saved in /kaggle/working 49-th batch\nAugmented images saved in /kaggle/working 50-th batch\nAugmented images saved in /kaggle/working 51-th batch\nAugmented images saved in /kaggle/working 52-th batch\nAugmented images saved in /kaggle/working 53-th batch\nAugmented images saved in /kaggle/working 54-th batch\nAugmented images saved in /kaggle/working 55-th batch\nAugmented images saved in /kaggle/working 56-th batch\nAugmented images saved in /kaggle/working 57-th batch\nAugmented images saved in /kaggle/working 58-th batch\nAugmented images saved in /kaggle/working 59-th batch\nAugmented images saved in /kaggle/working 60-th batch\nAugmented images saved in /kaggle/working 61-th batch\nAugmented images saved in /kaggle/working 62-th batch\nAugmented images saved in /kaggle/working 63-th batch\nAugmented images saved in /kaggle/working 64-th batch\nAugmented images saved in /kaggle/working 65-th batch\nAugmented images saved in /kaggle/working 66-th batch\nAugmented images saved in /kaggle/working 67-th batch\nAugmented images saved in /kaggle/working 68-th batch\nAugmented images saved in /kaggle/working 69-th batch\nAugmented images saved in /kaggle/working 70-th batch\nAugmented images saved in /kaggle/working 71-th batch\nAugmented images saved in /kaggle/working 72-th batch\nAugmented images saved in /kaggle/working 73-th batch\nAugmented images saved in /kaggle/working 74-th batch\nAugmented images saved in /kaggle/working 75-th batch\nAugmented images saved in /kaggle/working 76-th batch\nAugmented images saved in /kaggle/working 77-th batch\nAugmented images saved in /kaggle/working 78-th batch\nAugmented images saved in /kaggle/working 79-th batch\nAugmented images saved in /kaggle/working 80-th batch\nAugmented images saved in /kaggle/working 81-th batch\nAugmented images saved in /kaggle/working 82-th batch\nAugmented images saved in /kaggle/working 83-th batch\nAugmented images saved in /kaggle/working 84-th batch\nAugmented images saved in /kaggle/working 85-th batch\nAugmented images saved in /kaggle/working 86-th batch\nAugmented images saved in /kaggle/working 87-th batch\nAugmented images saved in /kaggle/working 88-th batch\nAugmented images saved in /kaggle/working 89-th batch\nAugmented images saved in /kaggle/working 90-th batch\nAugmented images saved in /kaggle/working 91-th batch\nAugmented images saved in /kaggle/working 92-th batch\nAugmented images saved in /kaggle/working 93-th batch\nAugmented images saved in /kaggle/working 94-th batch\nAugmented images saved in /kaggle/working 95-th batch\nAugmented images saved in /kaggle/working 96-th batch\nAugmented images saved in /kaggle/working 97-th batch\nAugmented images saved in /kaggle/working 98-th batch\nAugmented images saved in /kaggle/working 99-th batch\nAugmented images saved in /kaggle/working 100-th batch\nAugmented images saved in /kaggle/working 101-th batch\nAugmented images saved in /kaggle/working 102-th batch\nAugmented images saved in /kaggle/working 103-th batch\nAugmented images saved in /kaggle/working 104-th batch\nAugmented images saved in /kaggle/working 105-th batch\nAugmented images saved in /kaggle/working 106-th batch\nAugmented images saved in /kaggle/working 107-th batch\nAugmented images saved in /kaggle/working 108-th batch\nAugmented images saved in /kaggle/working 109-th batch\nAugmented images saved in /kaggle/working 110-th batch\nAugmented images saved in /kaggle/working 111-th batch\nAugmented images saved in /kaggle/working 112-th batch\nAugmented images saved in /kaggle/working 113-th batch\nAugmented images saved in /kaggle/working 114-th batch\nAugmented images saved in /kaggle/working 115-th batch\nAugmented images saved in /kaggle/working 116-th batch\nAugmented images saved in /kaggle/working 117-th batch\nAugmented images saved in /kaggle/working 118-th batch\nAugmented images saved in /kaggle/working 119-th batch\nAugmented images saved in /kaggle/working 120-th batch\nAugmented images saved in /kaggle/working 121-th batch\nAugmented images saved in /kaggle/working 122-th batch\nAugmented images saved in /kaggle/working 123-th batch\nAugmented images saved in /kaggle/working 124-th batch\nAugmented images saved in /kaggle/working 125-th batch\nAugmented images saved in /kaggle/working 126-th batch\nAugmented images saved in /kaggle/working 127-th batch\nAugmented images saved in /kaggle/working 128-th batch\nAugmented images saved in /kaggle/working 129-th batch\nAugmented images saved in /kaggle/working 130-th batch\nAugmented images saved in /kaggle/working 131-th batch\nAugmented images saved in /kaggle/working 132-th batch\nAugmented images saved in /kaggle/working 133-th batch\nAugmented images saved in /kaggle/working 134-th batch\nAugmented images saved in /kaggle/working 135-th batch\nAugmented images saved in /kaggle/working 136-th batch\nAugmented images saved in /kaggle/working 137-th batch\nAugmented images saved in /kaggle/working 138-th batch\nAugmented images saved in /kaggle/working 139-th batch\nAugmented images saved in /kaggle/working 140-th batch\nAugmented images saved in /kaggle/working 141-th batch\nAugmented images saved in /kaggle/working 142-th batch\nAugmented images saved in /kaggle/working 143-th batch\nAugmented images saved in /kaggle/working 144-th batch\nAugmented images saved in /kaggle/working 145-th batch\nAugmented images saved in /kaggle/working 146-th batch\nAugmented images saved in /kaggle/working 147-th batch\nAugmented images saved in /kaggle/working 148-th batch\nAugmented images saved in /kaggle/working 149-th batch\nAugmented images saved in /kaggle/working 150-th batch\nAugmented images saved in /kaggle/working 151-th batch\nAugmented images saved in /kaggle/working 152-th batch\nAugmented images saved in /kaggle/working 153-th batch\nAugmented images saved in /kaggle/working 154-th batch\nAugmented images saved in /kaggle/working 155-th batch\nAugmented images saved in /kaggle/working 156-th batch\nAugmented images saved in /kaggle/working 157-th batch\nAugmented images saved in /kaggle/working 158-th batch\nAugmented images saved in /kaggle/working 159-th batch\nAugmented images saved in /kaggle/working 160-th batch\nAugmented images saved in /kaggle/working 161-th batch\nAugmented images saved in /kaggle/working 162-th batch\nAugmented images saved in /kaggle/working 163-th batch\nAugmented images saved in /kaggle/working 164-th batch\nAugmented images saved in /kaggle/working 165-th batch\nAugmented images saved in /kaggle/working 166-th batch\nAugmented images saved in /kaggle/working 167-th batch\nAugmented images saved in /kaggle/working 168-th batch\nAugmented images saved in /kaggle/working 169-th batch\nAugmented images saved in /kaggle/working 170-th batch\nAugmented images saved in /kaggle/working 171-th batch\nAugmented images saved in /kaggle/working 172-th batch\nAugmented images saved in /kaggle/working 173-th batch\nAugmented images saved in /kaggle/working 174-th batch\nAugmented images saved in /kaggle/working 175-th batch\nAugmented images saved in /kaggle/working 176-th batch\nAugmented images saved in /kaggle/working 177-th batch\nAugmented images saved in /kaggle/working 178-th batch\nAugmented images saved in /kaggle/working 179-th batch\nAugmented images saved in /kaggle/working 180-th batch\nAugmented images saved in /kaggle/working 181-th batch\nAugmented images saved in /kaggle/working 182-th batch\nAugmented images saved in /kaggle/working 183-th batch\nAugmented images saved in /kaggle/working 184-th batch\nAugmented images saved in /kaggle/working 185-th batch\nAugmented images saved in /kaggle/working 186-th batch\nAugmented images saved in /kaggle/working 187-th batch\nAugmented images saved in /kaggle/working 188-th batch\nAugmented images saved in /kaggle/working 189-th batch\nAugmented images saved in /kaggle/working 190-th batch\nAugmented images saved in /kaggle/working 191-th batch\nAugmented images saved in /kaggle/working 192-th batch\nAugmented images saved in /kaggle/working 193-th batch\nAugmented images saved in /kaggle/working 194-th batch\nAugmented images saved in /kaggle/working 195-th batch\nAugmented images saved in /kaggle/working 196-th batch\nAugmented images saved in /kaggle/working 197-th batch\nAugmented images saved in /kaggle/working 198-th batch\nAugmented images saved in /kaggle/working 199-th batch\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Trying YOLO v5 with speed detection\n","metadata":{}},{"cell_type":"code","source":"# import torch\n# import cv2\n# import numpy as np\n\n# # Load the YOLOv5 model correctly from the ultralytics repository\n# model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n\n# # Path to the folder containing the frames\n# image_folder = '/kaggle/input/ua-detrac-dataset/content/UA-DETRAC/DETRAC_Upload/images/train'\n\n# # Frame rate of the video (e.g., 30 FPS)\n# frame_rate = 30\n\n# # Conversion factor from pixels to real-world speed (you need camera calibration for this)\n# pixel_to_speed_conversion = 0.05  # Example value, needs to be calibrated\n\n# # Function to calculate speed\n# def calculate_speed(displacement, time_interval):\n#     return displacement * pixel_to_speed_conversion / time_interval\n\n# # Load frames\n# def load_frames(image_folder):\n#     images = []\n#     for filename in sorted(os.listdir(image_folder)):\n#         if filename.endswith(\".jpg\"):  \n#             img = cv2.imread(os.path.join(image_folder, filename))\n#             images.append(img)\n#     return images\n\n# # Track vehicles and calculate speed\n# def track_and_calculate_speed(frames, model, frame_rate):\n#     speeds = []\n#     prev_frame_boxes = None\n\n#     for i in range(1, len(frames)):\n#         # Detect vehicles in the current frame\n#         results = model(frames[i])\n#         current_frame_boxes = results.xyxy[0].cpu().numpy()  # Bounding box coordinates (x1, y1, x2, y2)\n\n#         # If this is not the first frame, track and calculate speed\n#         if prev_frame_boxes is not None:\n#             # For simplicity, let's assume we are matching vehicles by the closest bounding boxes\n#             for j, current_box in enumerate(current_frame_boxes):\n#                 # Find the closest bounding box from the previous frame\n#                 prev_box = min(prev_frame_boxes, key=lambda box: np.linalg.norm(current_box[:2] - box[:2]))\n\n#                 # Calculate the displacement (center points of the bounding boxes)\n#                 current_center = np.array([(current_box[0] + current_box[2]) / 2, (current_box[1] + current_box[3]) / 2])\n#                 prev_center = np.array([(prev_box[0] + prev_box[2]) / 2, (prev_box[1] + prev_box[3]) / 2])\n#                 displacement = np.linalg.norm(current_center - prev_center)\n\n#                 # Calculate the speed (displacement / time interval)\n#                 time_interval = 1 / frame_rate\n#                 speed = calculate_speed(displacement, time_interval)\n#                 speeds.append((i, speed))  # Store the frame index and speed for annotation\n\n#         # Update previous frame boxes for the next iteration\n#         prev_frame_boxes = current_frame_boxes\n\n#     return speeds\n\n# # Load the frames\n# frames = load_frames(image_folder)\n\n# # Track and calculate speeds\n# speeds = track_and_calculate_speed(frames, model, frame_rate)\n\n# # Display calculated speeds\n# for frame_index, speed in speeds:\n#     print(f\"Frame {frame_index}: Speed = {speed:.2f} units\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T10:18:46.901263Z","iopub.execute_input":"2024-11-03T10:18:46.901981Z","iopub.status.idle":"2024-11-03T10:18:46.910638Z","shell.execute_reply.started":"2024-11-03T10:18:46.901926Z","shell.execute_reply":"2024-11-03T10:18:46.909305Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# import torch.optim as optim\n# from torch.utils.data import Dataset, DataLoader\n\n# # Define custom dataset class\n# class VehicleSpeedDataset(Dataset):\n#     def __init__(self, image_folder, annotations):\n#         self.images = sorted(os.listdir(image_folder))\n#         self.annotations = annotations  # Assuming annotations is a list of (bounding_box, speed) tuples\n\n#     def __len__(self):\n#         return len(self.images)\n\n#     def __getitem__(self, idx):\n#         img_path = os.path.join(image_folder, self.images[idx])\n#         image = cv2.imread(img_path)\n#         bbox, speed = self.annotations[idx]\n#         return image, bbox, speed\n\n# # Define model architecture\n# class SpeedDetectionModel(nn.Module):\n#     def __init__(self, pretrained_model):\n#         super(SpeedDetectionModel, self).__init__()\n#         self.base_model = pretrained_model  # Pre-trained YOLOv5 or other detection model\n#         self.fc = nn.Linear(1024, 1)  # Add a fully connected layer for speed prediction\n\n#     def forward(self, x):\n#         features = self.base_model(x)\n#         speed = self.fc(features)  # Predict speed\n#         return speed\n\n# # Load pre-trained YOLO model\n# yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n\n# # Create your speed detection model\n# model = SpeedDetectionModel(yolo_model)\n\n# # Define loss function and optimizer\n# criterion = nn.MSELoss()  # Mean Squared Error for regression\n# optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# # Train the model\n# def train_model(model, train_loader, num_epochs=10):\n#     model.train()\n#     for epoch in range(num_epochs):\n#         running_loss = 0.0\n#         for images, bboxes, speeds in train_loader:\n#             optimizer.zero_grad()\n#             outputs = model(images)\n#             loss = criterion(outputs, speeds)\n#             loss.backward()\n#             optimizer.step()\n#             running_loss += loss.item()\n\n#         print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')\n\n# # Prepare dataset and dataloader\n# annotations = [(bbox, speed) for bbox, speed in zip(bboxes_list, speed_list)]\n# train_dataset = VehicleSpeedDataset(image_folder, annotations)\n# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n\n# # Train the model\n# train_model(model, train_loader)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-03T10:18:46.913379Z","iopub.execute_input":"2024-11-03T10:18:46.914169Z","iopub.status.idle":"2024-11-03T10:18:46.935427Z","shell.execute_reply.started":"2024-11-03T10:18:46.914111Z","shell.execute_reply":"2024-11-03T10:18:46.934124Z"},"trusted":true},"execution_count":4,"outputs":[]}]}